# Performance Configuration for Agent-First Context System
# This file contains tunable parameters for optimizing performance

vector_db:
  # Embedding configuration
  embedding:
    batch_size: 100  # Number of documents to embed in parallel
    max_retries: 3
    initial_retry_delay: 1.0  # seconds
    retry_backoff_factor: 2.0
    request_timeout: 30  # seconds
    
  # Search optimization
  search:
    default_limit: 10
    max_limit: 100
    ef_search: 128  # HNSW search parameter
    
  # Indexing parameters
  indexing:
    flush_interval_sec: 5
    max_segment_size: 200_000
    memmap_threshold: 100_000
    
  # Cache settings
  cache:
    enabled: true
    max_entries: 10000
    ttl_seconds: 3600  # 1 hour

graph_db:
  # Connection pool settings
  connection_pool:
    min_size: 1
    max_size: 10
    acquisition_timeout: 60  # seconds
    
  # Query optimization
  query:
    max_path_length: 5  # Maximum hops in graph traversal
    default_limit: 50
    query_timeout: 30  # seconds
    use_query_cache: true
    
  # Batch processing
  batch:
    size: 1000  # Number of nodes/relationships per batch
    parallel_transactions: 4
    
  # Graph algorithms
  algorithms:
    pagerank_iterations: 20
    community_detection_resolution: 1.0

search:
  # Sum-of-scores configuration
  ranking:
    temporal_decay_days: 30  # Start decay after this many days
    temporal_decay_rate: 0.01  # Decay rate per day
    
    # Document type boost factors
    type_boosts:
      architecture: 1.25
      design: 1.20
      decision: 1.15
      sprint: 1.10
      api: 1.00
      test: 0.90
      documentation: 0.85
    
  # GraphRAG settings
  graphrag:
    max_graph_hops: 2
    context_weight: 0.3  # Weight for graph context in final score
    min_similarity_threshold: 0.7

# Resource limits
resources:
  max_memory_gb: 4
  max_cpu_percent: 80
  disk_cache_size_gb: 10
  
# Key-Value store performance
kv_store:
  redis:
    connection_pool:
      min_size: 5
      max_size: 50
      timeout: 5
    cache:
      ttl_seconds: 3600
      max_entries: 10000
    pipeline:
      batch_size: 100
      flush_interval_ms: 50
  
  duckdb:
    batch_insert:
      size: 1000
      timeout_seconds: 30
    query:
      timeout_seconds: 60
      max_results: 10000
    analytics:
      aggregation_interval: "5 minutes"
      retention_days: 90
  
# Monitoring
monitoring:
  metrics_enabled: true
  metrics_interval_seconds: 60
  slow_query_threshold_ms: 1000
  log_level: "INFO"  # DEBUG, INFO, WARNING, ERROR