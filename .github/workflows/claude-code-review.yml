---
###############################################################################
# 🛠️  Enhanced GitHub Workflow — Claude Code Review (Agent-First, ARC-Reviewer)
# Version: 2025-01-15 with suggested improvements
###############################################################################
name: Claude Code Review
on:
  pull_request:
    types: [opened, synchronize, closed]
    # paths:
    #   - "src/**"
    #   - "context/**"
    #   - "tests/**"
    #   - "*.md"
    #   - "*.yaml"
    #   - "*.yml"

jobs:
  claude-pr-review:
    if: github.event.action != 'closed'
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write      # allow comment / approval
      issues: write             # allow auto-file follow-up issues
      statuses: write           # allow setting commit status
      id-token: write           # for future Sigstore attestation

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0        # full history for context diff

      - name: Setup Python and Node
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
          pip install -r requirements-test.txt
          pip install yamale
          npm install -g ajv-cli

      - name: Create directories
        run: |
          mkdir -p context/.duckdb
          mkdir -p context/.graph_cache
          mkdir -p context/.vector_cache
          mkdir -p context/.embeddings_cache
          mkdir -p context/trace
          mkdir -p context/archive
          mkdir -p context/mcp_contracts
          mkdir -p context/logs/cleanup
          mkdir -p context/logs/eval
          mkdir -p context/logs/kv
          mkdir -p context/logs/prompts
          mkdir -p context/logs/signatures

      - name: Run Claude Code Review
        id: claude-review
        uses: anthropics/claude-code-action@beta
        with:
          claude_code_oauth_token: ${{ secrets.CLAUDE_CODE_OAUTH_TOKEN }}
          model: "claude-opus-4-20250514"
          # -------- ARC-Reviewer Prompt --------
          direct_prompt: |
            You are ARC-Reviewer, a senior staff engineer reviewing pull-requests on the agent-context-template (MCP-based context platform).

            CRITICAL: Output ONLY valid YAML. No markdown, no explanations, no code blocks. Start directly with the YAML schema.

            Review criteria (any failure = REQUEST_CHANGES):
            - Test Coverage: validators/* ≥ 90%, overall ≥ 78.0%
            - MCP Compatibility: Tool contracts updated, valid JSON schema
            - Context Integrity: All YAML has schema_version, context/ structure intact
            - Code Quality: Python typed, docstrings, pre-commit passes
            - Security: Dockerfiles pinned digests, no secrets, CVE-free deps

            For blocking issues, be specific about:
            - What is wrong (description)
            - Where it's located (file and line)
            - What category it falls under
            - How to fix it (actionable guidance)

            Output this exact YAML structure (replace bracketed values with actuals):

            schema_version: "1.0"
            pr_number: [ACTUAL_PR_NUMBER]
            timestamp: "[CURRENT_ISO_TIMESTAMP]"
            reviewer: "ARC-Reviewer"
            verdict: "APPROVE"
            summary: "Brief review summary"
            coverage:
              current_pct: [ACTUAL_PERCENTAGE]
              status: "PASS"
              meets_baseline: true
            issues:
              blocking:
                - description: "Specific actionable description of what must be fixed"
                  file: "relative/path/to/file.py"
                  line: 42
                  category: "test_coverage"
                  fix_guidance: "Add unit tests for the new function"
              warnings:
                - description: "High-priority improvement needed"
                  file: "path/to/file.py"
                  line: 15
                  category: "code_quality"
                  fix_guidance: "Add type hints to this function"
              nits:
                - description: "Style or minor improvement"
                  file: "path/to/file.py"
                  line: 8
                  category: "style"
                  fix_guidance: "Use more descriptive variable name"
            automated_issues:
              - title: "Follow-up issue title"
                description: "Detailed description for GitHub issue"
                labels: ["enhancement", "test"]
                phase: "4.1"
                priority: "high"
                category: "test_coverage"
          # enable sticky threaded comment
          use_sticky_comment: true
          # Tools Claude may invoke during review
          allowed_tools: |
            Bash(pytest --cov=src --cov-report=term --cov-report=json -m "not integration and not e2e"),
            Bash(pre-commit run --all-files --config .pre-commit-config-ci.yaml),
            Bash(python -m src.validators.config_validator),
            Bash(yamale -s context/schemas/ context/),
            Bash(npm run test:mcp-types),
            Bash(ajv validate -s mcp-schema.json -d context/mcp_contracts/*.json),
            Bash(git diff --name-only origin/main...HEAD)

      # ---------- Load Coverage Configuration ----------
      - name: Load Coverage Configuration
        id: load-config
        run: |
          # Load baseline and tolerance buffer
          config=$(python -c "import json; data=json.load(open('.coverage-config.json')); \
                      print(f\"{data['baseline']},{data.get('tolerance_buffer', 0.0)}\")")
          baseline=$(echo "$config" | cut -d',' -f1)
          tolerance=$(echo "$config" | cut -d',' -f2)
          effective_baseline=$(python -c "print(max(0, $baseline - $tolerance))")
          echo "COVERAGE_BASELINE=$effective_baseline" >> $GITHUB_ENV
          echo "Coverage baseline loaded: $baseline% (effective: $effective_baseline% with $tolerance% tolerance)"

      # ---------- Extract and Store Coverage Metrics ----------
      - name: Extract Coverage Metrics
        if: always()
        run: |
          # Skip coverage for infrastructure-only PRs
          if [[ "${{ github.head_ref }}" == *"docker-compose"* ]] || \
             [[ "${{ github.head_ref }}" == *"infra"* ]] || \
             [[ "${{ github.head_ref }}" == *"workflow"* ]] || \
             [[ "${{ github.head_ref }}" == *"fix/28"* ]]; then
            echo "Skipping coverage check for infrastructure PR"
            echo "COVERAGE_PCT=${{ env.COVERAGE_BASELINE }}" >> $GITHUB_ENV
            # Set to baseline to avoid failure
            echo "COVERAGE_FAILED=false" >> $GITHUB_ENV
            echo "INFRASTRUCTURE_PR=true" >> $GITHUB_ENV
          else
            # Run coverage and capture output (exclude integration/e2e tests like main test workflow)
            echo "Running coverage analysis..."
            pytest tests/ --cov=src --cov-report=term --cov-report=json -m "not integration and not e2e" || true

            # Debug: Check if coverage.json was created
            if [ -f coverage.json ]; then
              echo "✓ coverage.json created successfully"
              ls -la coverage.json

              # Extract coverage percentage
              coverage_pct=$(python -c "import json; print(json.load(open('coverage.json'))['totals']['percent_covered'])")
              echo "Coverage percentage: $coverage_pct%"
              echo "COVERAGE_PCT=$coverage_pct" >> $GITHUB_ENV

              # Check if coverage dropped below baseline
              if (( $(echo "$coverage_pct < ${{ env.COVERAGE_BASELINE }}" | bc -l) )); then
                echo "❌ Coverage below baseline: $coverage_pct% < ${{ env.COVERAGE_BASELINE }}%"
                echo "COVERAGE_FAILED=true" >> $GITHUB_ENV
              else
                echo "✓ Coverage meets baseline: $coverage_pct% >= ${{ env.COVERAGE_BASELINE }}%"
                echo "COVERAGE_FAILED=false" >> $GITHUB_ENV
              fi
            else
              echo "❌ coverage.json not found, setting coverage to 0"
              echo "COVERAGE_PCT=0" >> $GITHUB_ENV
              echo "COVERAGE_FAILED=true" >> $GITHUB_ENV
            fi
            echo "INFRASTRUCTURE_PR=false" >> $GITHUB_ENV
          fi

      # ---------- Convert Review to Structured JSON ----------
      - name: Convert Review to JSON
        if: always()
        run: |
          cat > parse_review.py << 'EOF'
          import sys
          import json
          import re

          # Read review content from file
          try:
              with open('review.txt', 'r') as f:
                  review_text = f.read()
          except FileNotFoundError:
              review_text = sys.argv[1] if len(sys.argv) > 1 else ""

          # Parse structured review
          verdict_match = re.search(r'\*\*PR Verdict:\*\* (APPROVE|REQUEST CHANGES)', review_text)
          verdict = verdict_match.group(1) if verdict_match else "UNKNOWN"

          # Extract sections
          blocking = re.findall(r'(?<=Blocking Issues \(❌\):)(.*?)(?=\*\*|$)', review_text, re.DOTALL)
          warnings = re.findall(r'(?<=Warnings \(⚠️\):)(.*?)(?=\*\*|$)', review_text, re.DOTALL)
          nits = re.findall(r'(?<=Nits \(💡\):)(.*?)(?=\*\*|$)', review_text, re.DOTALL)
          followups = re.findall(r'(?<=Suggested Follow-ups:)(.*?)(?=End of report|$)', review_text, re.DOTALL)

          review_json = {
              "verdict": verdict,
              "has_blockers": bool(blocking and blocking[0].strip()),
              "coverage_pct": float(sys.argv[2]) if len(sys.argv) > 2 else None,
              "sections": {
                  "blocking": blocking[0].strip() if blocking else "",
                  "warnings": warnings[0].strip() if warnings else "",
                  "nits": nits[0].strip() if nits else "",
                  "followups": followups[0].strip() if followups else ""
              }
          }

          print(json.dumps(review_json, indent=2))
          EOF

          # Use review.txt if available, otherwise fallback to action output
          if [ -f review.txt ]; then
            python parse_review.py "" "${COVERAGE_PCT:-0}" > review.json
          else
            python parse_review.py "${{ steps.claude-review.outputs.response }}" "${COVERAGE_PCT:-0}" > review.json
          fi

          # Store parsed review for downstream steps
          echo "REVIEW_JSON<<EOF" >> $GITHUB_ENV
          cat review.json >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV

      # ---------- Set GitHub Status Check ----------
      - name: Set Commit Status
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const review = ${{ env.REVIEW_JSON }};
            const coverage_pct = parseFloat("${{ env.COVERAGE_PCT }}") || 0;

            // Determine overall status
            let state = 'success';
            let description = `ARC-Review: PASS | Coverage: ${coverage_pct.toFixed(1)}%`;
            const isInfrastructurePR = "${{ env.INFRASTRUCTURE_PR }}" === "true";

            if (review.verdict === 'REQUEST CHANGES' || review.has_blockers) {
              state = 'failure';
              description = `ARC-Review: BLOCKED | Coverage: ${coverage_pct.toFixed(1)}%`;
            } else if (!isInfrastructurePR && coverage_pct < parseFloat("${{ env.COVERAGE_BASELINE }}")) {
              state = 'failure';
              description = `ARC-Review: Coverage regression (${coverage_pct.toFixed(1)}% < ${{ env.COVERAGE_BASELINE }}%)`;
            } else if (isInfrastructurePR) {
              description = `ARC-Review: PASS (Infrastructure PR) | Coverage: skipped`;
            }

            // Create status check
            await github.rest.repos.createCommitStatus({
              owner: context.repo.owner,
              repo: context.repo.repo,
              sha: context.payload.pull_request.head.sha,
              state: state,
              description: description,
              context: 'ARC-Reviewer'
            });

      # ---------- Create Agent-First Automation Comment ----------
      - name: Create Automation Comment
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            // ROBUST: Handle Claude action output bug with fallback
            let reviewResponse = `${{ steps.claude-review.outputs.response }}`;

            console.log(`Action output length: ${reviewResponse.length}`);
            console.log(`Action output preview: ${reviewResponse.substring(0, 200)}...`);

            // FALLBACK: If action output is empty, fetch from PR comments
            if (!reviewResponse || reviewResponse.trim() === '') {
              console.log('Action output empty, fetching from PR comments...');

              const comments = await github.rest.issues.listComments({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number
              });

              // Find Claude's review comment (most recent with automation JSON)
              const claudeComment = comments.data
                .filter(comment => comment.body.includes('automated_issues'))
                .pop(); // Get the most recent

              if (claudeComment) {
                reviewResponse = claudeComment.body;
                console.log(`Found Claude comment with automation data: ${reviewResponse.length} chars`);
              }
            }

            // ROBUST: Better JSON extraction with multiple strategies
            function extractAutomationJSON(text) {
              // Strategy 1: Standard JSON blocks
              let match = text.match(/```json\s*(\{[\s\S]*?"automated_issues"[\s\S]*?\})\s*```/);
              if (match) return match[1];

              // Strategy 2: Handle escaped JSON
              match = text.match(/```json\s*(\{[^`]*"automated_issues"[^`]*\})\s*```/);
              if (match) return match[1];

              // Strategy 3: Find JSON object with automated_issues anywhere
              match = text.match(/(\{[^{}]*"automated_issues"[^{}]*\})/);
              if (match) return match[1];

              return null;
            }

            const jsonString = extractAutomationJSON(reviewResponse);
            console.log(`Extracted JSON: ${jsonString ? 'Found' : 'Not found'}`);

            if (jsonString) {
              try {
                const issuesData = JSON.parse(jsonString);
                if (issuesData.automated_issues && Array.isArray(issuesData.automated_issues) && issuesData.automated_issues.length > 0) {

                  // ROBUST: Build YAML with proper escaping
                  let yamlContent = `# ARC-Automation\nschema_version: "1.0"\nsource_pr: ${context.issue.number}\n` +
                    `generated_at: "${new Date().toISOString()}"\nautomated_issues:\n`;

                  for (const issue of issuesData.automated_issues) {
                    // Sanitize strings for YAML
                    const sanitize = (str) => str.replace(/"/g, '\\"').replace(/\n/g, '\\n').replace(/\r/g, '');

                    yamlContent += `  - title: "${sanitize(issue.title || 'Untitled')}"\n`;
                    yamlContent += `    description: "${sanitize(issue.description || 'No description')}"\n`;
                    yamlContent += `    labels: [${(issue.labels || []).map(l => `"${sanitize(l)}"`).join(', ')}]\n`;
                    yamlContent += `    phase: "${sanitize(issue.phase || 'backlog')}"\n`;
                  }

                  // Create the automation comment
                  await github.rest.issues.createComment({
                    issue_number: context.issue.number,
                    owner: context.repo.owner,
                    repo: context.repo.repo,
                    body: `<!-- ARC-AUTOMATION -->\n\`\`\`yaml\n${yamlContent}\n\`\`\``
                  });

                  console.log(`✅ Created automation comment with ${issuesData.automated_issues.length} issues`);
                } else {
                  console.log('No valid automated_issues array found in JSON');
                }
              } catch (e) {
                console.log(`❌ Failed to parse automation JSON: ${e.message}`);
                console.log(`Raw JSON: ${jsonString.substring(0, 500)}...`);
              }
            } else {
              console.log('No automation JSON found in review content');
            }
      # ---------- Upload Coverage Report ----------
      - name: Upload Coverage Report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: coverage-report
          path: |
            htmlcov/
            coverage.json
            review.json

      # ---------- Add PR Comment with Coverage Badge ----------
      - name: Add Coverage Badge Comment
        if: always()
        uses: actions/github-script@v7
        with:
          script: |
            const coverage_pct = parseFloat("${{ env.COVERAGE_PCT }}") || 0;
            const coverage_color = coverage_pct >= 85 ? 'brightgreen' :
                                  coverage_pct >= 70 ? 'yellow' :
                                  coverage_pct >= 60 ? 'orange' : 'red';

            const badge_url = `https://img.shields.io/badge/coverage-${coverage_pct.toFixed(1)}%25-${coverage_color}`;

            const comment = `## 🤖 ARC-Reviewer Report

            ![Coverage](${badge_url})

            ${context.payload.pull_request.body || ''}`;

            // Only add badge if not already present
            if (!context.payload.pull_request.body?.includes('img.shields.io/badge/coverage')) {
              github.rest.pulls.update({
                owner: context.repo.owner,
                repo: context.repo.repo,
                pull_number: context.issue.number,
                body: comment
              });
            }

      # ---------- Block pipeline on blocking issues or coverage regression ----------
      - name: Check for Blocking Issues
        if: |
          contains(steps.claude-review.outputs.response, 'REQUEST CHANGES') ||
          contains(steps.claude-review.outputs.response, 'Blocking Issues (❌):') ||
          env.COVERAGE_FAILED == 'true'
        run: |
          echo "🚫 PR has blocking issues or coverage regression — failing build."
          echo "Review verdict: ${{ fromJson(env.REVIEW_JSON).verdict }}"
          echo "Coverage: ${{ env.COVERAGE_PCT }}% (minimum: ${{ env.COVERAGE_BASELINE }}%)"
          exit 1

      - name: Success Message
        if: success()
        run: |
          echo "✅ PR cleared ARC-Reviewer!"
          echo "- No blocking issues found"
          echo "- Coverage: ${{ env.COVERAGE_PCT }}% ✓"
          echo "- Ready to merge after human review"


  # Agent-First Post-merge job to process automation data
  create-follow-up-issues:
    if: github.event.action == 'closed' && github.event.pull_request.merged == true
    runs-on: ubuntu-latest
    permissions:
      contents: read
      issues: write
      pull-requests: read

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Process Automation Data
        env:
          GH_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          pr_num="${{ github.event.pull_request.number }}"

          echo "Processing automation data for PR #$pr_num"

          # Get automation comment
          gh api "repos/${{ github.repository }}/issues/$pr_num/comments" \
            --jq '.[] | select(.body | contains("ARC-AUTOMATION")) | .body' > automation.txt || echo ""

          if [ -s automation.txt ]; then
            # Extract and process YAML
            python3 << 'PYEOF'
          import re
          import yaml

          with open('automation.txt', 'r') as f:
              content = f.read()

          yaml_match = re.search(r'```yaml\s*\n(.*?)\n```', content, re.DOTALL)
          if yaml_match:
              try:
                  data = yaml.safe_load(yaml_match.group(1))
                  issues = data.get('automated_issues', [])

                  if issues:
                      print(f"Found {len(issues)} automation issues")

                      # Create aggregated issue
                      import subprocess
                      import json

                      # Ensure labels exist
                      for label in ['from-code-review', 'sprint-triage', 'phase=backlog']:
                          subprocess.run(['gh', 'label', 'create', label, '--force'],
                                       capture_output=True, text=True)

                      # Build issue content
                      checklist = []
                      for issue in issues:
                          title = issue['title']
                          desc = issue['description']
                          phase = issue['phase']
                          checklist.append(f"- [ ] **{title}**: {desc} (phase: {phase})")

                      pr_num = "${{ github.event.pull_request.number }}"
                      pr_url = "${{ github.event.pull_request.html_url }}"
                      pr_author = "${{ github.event.pull_request.user.login }}"

                      # Build issue content safely
                      issue_body = "## Automated Follow-ups from PR #" + pr_num + "\n\n"
                      issue_body += "Source: " + pr_url + "\n"
                      issue_body += "Author: @" + pr_author + "\n\n"
                      issue_body += "## Issues to Triage\n\n"
                      issue_body += "\n".join(checklist) + "\n\n"
                      issue_body += "## Instructions\n\n"
                      issue_body += "For agents/PMs: Review, prioritize, and move high-value items to sprint YAML files.\n\n"
                      issue_body += "---\n"
                      issue_body += "Auto-generated by ARC-Reviewer"

                      with open('issue_body.md', 'w') as f:
                          f.write(issue_body)

                      # Create the issue
                      result = subprocess.run([
                          'gh', 'issue', 'create',
                          '--title', f'[PR #{pr_num}] ARC-Reviewer Follow-ups',
                          '--body-file', 'issue_body.md',
                          '--label', 'from-code-review,sprint-triage,phase=backlog'
                      ], capture_output=True, text=True)

                      if result.returncode == 0:
                          print(f"✅ Created aggregated issue: {result.stdout.strip()}")
                      else:
                          print(f"❌ Failed to create issue: {result.stderr}")
                  else:
                      print("No automation issues found")
              except Exception as e:
                  print(f"Error processing automation data: {e}")
          else:
              print("No automation comment found")
          PYEOF
          else
            echo "No automation data found for this PR"
          fi
